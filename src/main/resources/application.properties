quarkus.langchain4j.ollama.llama3.timeout=180s
quarkus.langchain4j.ollama.llama3.chat-model.model-id=llama3-groq-tool-use
quarkus.langchain4j.ollama.llama3.chat-model.temperature=0
quarkus.langchain4j.ollama.llama3.chat-model.top-k=40
quarkus.langchain4j.ollama.llama3.chat-model.top-p=0.8
quarkus.langchain4j.log-requests=false
quarkus.langchain4j.log-responses=true

quarkus.log.category."org.kie.kogito".level=DEBUG